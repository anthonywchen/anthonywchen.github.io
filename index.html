<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8" />
	<title>Anthony Chen</title>
	<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
		integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
</head>

<body>
	<div class="container mt-4">
		<!-- INTRODUCTION -->
		<h1>Anthony Chen</h1>
		<div class="row">
			<div class="col-lg-3 col-md-4 order-0 order-xs-0 order-sm-0 order-md-1 order-lg-1">
				<img width="250px" src="images/me.jpg" alt="">
			</div>
			<div class="col-lg-9 col-md-8 order-1 order-xs-1 order-sm-1 order-md-0 order-lg-0">
				<p class="lead">
					Welcome! I am a final-year Ph.D. student working on machine learning and language understanding at
					UC Irvine, advised by <a target="_blank" href="http://sameersingh.org/">Sameer Singh</a>.
					Previously, I was a research intern at Google hosted by <a target="_blank"
						href="https://research.google/people/HongraeLee/">Hongrae
						Lee</a> and <a target="_blank" href="https://www.kelvinguu.com/">Kelvin Guu</a> and before that
					I was a research intern at Verneek and Apple.
					I've also had the fortune to collaborate with <a target="_blank"
						href="https://gabrielstanovsky.github.io/">Gabi Stanovsky</a>
					and <a target="_blank" href="https://matt-gardner.github.io/">Matt Gardner</a>.

					<br><br>

					My research focuses on how we can evaluate the limits of large language models (<i>e.g.</i>,
					OpenAI's GPT-3 and Google's PALM) and design efficient
					methods to address their deficiencies.
					Recently, I've been tackling the pernicious problem of attribution and <a target="_blank"
						href="https://www.protocol.com/enterprise/openai-gptinstruct">hallucinations</a> in language
					models.
					My work is concerned with <a target="_blank" href=" https://arxiv.org/abs/2109.05052">understanding
						the cause of</a>
					and <a target="_blank" href="https://arxiv.org/abs/2210.08726">removing</a> hallucinations from the
					outputs of large language models, making them more reliable to use.
					<br><br>
					<center>
						<a href="email.html" target="_blank" class="btn btn-outline-info">Email</a>
						<a href="https://scholar.google.com/citations?user=n3PSuQMAAAAJ&hl=en" target="_blank"
							class="btn btn-outline-info">Google Scholar</a>
						<a href="https://twitter.com/_anthonychen" target="_blank"
							class="btn btn-outline-info">Twitter</a>
						<a href="CV.pdf" target="_blank" class="btn btn-outline-info">CV</a>
					</center>
				</p>
			</div>
		</div>

		<!-- NEWS -->
		<hr>
		<h2>Recent Stuff</h2>
		<ul>
			<b>May 2023 [Paper]</b> Work on <a target="_blank" href="https://bit.ly/3pZMX7j">PURR</a>, a
			post-hoc method efficiently editing language model hallucinations trained by denoising lanugage model
			corruptions, out now!
			<br><br>
			<b>May 2023 [Paper]</b> Work on <a target="_blank" href="https://arxiv.org/abs/2210.08726">RARR</a>, a
			post-hoc method for removing language model hallucinations, has been accepted to ACL!
			<br><br>
			<b>Oct 2022 [Paper]</b> Generation systems like large language models are known to hallucinate.
			However, re-training them to avoid these problems is costly.
			<a target="_blank" href="https://arxiv.org/abs/2210.08726">In our paper</a> with Google Research, we propose
			to edit generated text in a post-hoc fashion to remove hallucinations.
		</ul>

		<!-- RESEARCH -->
		<hr>
		<h2>Publications</h2>
		<ul>
			<span style="font-size:20px"><a target="_blank" href="https://bit.ly/3pZMX7j"> PURR: Efficiently
					Editing Language Model Hallucinations by Denoising
					Language Model Corruptions</a></span><br />
			<font color="green">Anthony Chen</font>, Panupong Pasupat, Sameer Singh, Hongrae Lee and Kelvin Guu<br />
			<i>arXiv</i>
			<br><br>

			<span style="font-size:20px"><a target="_blank" href="https://arxiv.org/abs/2210.08726">RARR: Researching
					and Revising What Language Models Say, Using Language
					Models</a></span><br />
			Luyu Gao, Zhuyun Dai, Panupong Pasupat, <font color="green">Anthony Chen</font>, Arun Tejasvi Chaganty,
			Yicheng Fan, Vincent Y. Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan and Kelvin Guu<br />
			<i>Association for Computational Linguistics (ACL) 2023</i>
			<br><br>

			<span style="font-size:20px"><a target="_blank" href="https://arxiv.org/abs/2109.05052">Entity-Based
					Knowledge Conflicts in Question Answering</a></span><br />
			Shayne Longpre, Kartik Perisetla, <font color="green">Anthony Chen</font>, Nikhil Ramesh, Chris DuBois and
			Sameer Singh <br />
			<i>Empirical Methods in Natural Language Processing (EMNLP) 2021</i> <br />
			<a target="_blank" href="https://machinelearning.apple.com/research/entity-knowledge-conflicts"
				class="btn btn-sm btn-outline-primary">Website</a>
			<a target="_blank" href="https://github.com/apple/ml-knowledge-conflicts"
				class="btn btn-sm btn-outline-primary">Code</a>
			<a target="_blank" href="Papers/knowledge_conflicts/slides.pdf"
				class="btn btn-sm btn-outline-primary">Slides</a>
			<a target="_blank" href="Papers/knowledge_conflicts/poster.pdf"
				class="btn btn-sm btn-outline-primary">Poster</a>
			<br><br>

			<span style="font-size:20px"><a target="_blank" href="https://arxiv.org/abs/2106.06830">Evaluating Entity
					Disambiguation and the Role of Popularity in Retrieval-Based NLP</a></span><br />
			<font color="green">Anthony Chen</font>, Pallavi Gudipati, Shayne Longpre, Xiao Ling and Sameer Singh <br />
			<i>Association for Computational Linguistics and the International Joint Conference on Natural Language
				Processing (ACL-IJCNLP) 2021</i> <br />
			<a target="_blank" href="https://machinelearning.apple.com/research/evaluating-entity-disambiguation-amber"
				class="btn btn-sm btn-outline-primary">Website</a>
			<a target="_blank" href="https://github.com/anthonywchen/AmbER-Sets/"
				class="btn btn-sm btn-outline-primary">Code</a>
			<a target="_blank" href="https://github.com/anthonywchen/AmbER-Sets/data/"
				class="btn btn-sm btn-outline-primary">Data</a>
			<a target="_blank" href="Papers/amber/amber_slides.pdf" class="btn btn-sm btn-outline-primary">Slides</a>
			<br><br>

			<span style="font-size:20px"><a target="_blank" href="https://arxiv.org/abs/2010.03636">MOCHA: A Dataset for
					Training and Evaluating Generative Reading Comprehension Metrics</a></span><br />
			<font color="green">Anthony Chen</font>, Gabriel Stanovsky, Sameer Singh, and Matt Gardner <br />
			<i>Empirical Methods in Natural Language Processing (EMNLP) 2020</i> <br />
			<a target="_blank" href="https://allennlp.org/mocha" class="btn btn-sm btn-outline-primary">Website</a>
			<a target="_blank" href="https://github.com/anthonywchen/MOCHA/"
				class="btn btn-sm btn-outline-primary">Code</a>
			<a target="_blank" href="https://github.com/anthonywchen/MOCHA/blob/main/data/mocha.tar.gz"
				class="btn btn-sm btn-outline-primary">Data</a>
			<a target="_blank" href="https://www.youtube.com/watch?v=ou5XGiv6zT8"
				class="btn btn-sm btn-outline-primary">Video</a>
			<a target="_blank" href="Papers/mocha/mocha_slides.pdf" class="btn btn-sm btn-outline-primary">Slides</a>
			<a target="_blank" href="https://demo.allennlp.org/evaluate-reading-comprehension"
				class="btn btn-sm btn-outline-primary">Demo</a>
			<br><br>

			<span style="font-size:20px"><a target="_blank" href="https://www.aclweb.org/anthology/D19-5817/">Evaluating
					Question Answering Evaluation</a></span><br />
			<font color="green">Anthony Chen</font>, Gabriel Stanovsky, Sameer Singh and Matt Gardner <br />
			<i>Machine Reading for Question Answering Workshop @ Empirical Methods in Natural Language Processing
				(EMNLP) 2019</i>
			<font color="red">Best Paper Award</font><br />
			<a target="_blank" href="Papers/evaluatingqa/correlation_data.zip"
				class="btn btn-sm btn-outline-primary">Data</a>
			<a target="_blank" href="Papers/evaluatingqa/mrqa_slides.pdf"
				class="btn btn-sm btn-outline-primary">Slides</a>
		</ul>

		<hr>
	</div>
</body>

</html>